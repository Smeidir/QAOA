{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75abf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.qaoa.models.MaxCutProblem import MaxCutProblem\n",
    "\n",
    "def visualize(data, x,y, hues, chart):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    match chart:\n",
    "        case 'line':\n",
    "            chart_type = sns.lineplot\n",
    "        case 'bar':\n",
    "            chart_type = sns.barplot\n",
    "        case 'box':\n",
    "            chart_type = sns.boxplot\n",
    "        case None:\n",
    "            chart_type = sns.plot\n",
    "\n",
    "    # make a copy to avoid modifying the original DataFrame and avoid warnings\n",
    "    data_to_plot = data.copy()\n",
    "\n",
    "    try:\n",
    "        if len(hues) > 1:\n",
    "            data_to_plot['hues'] = data_to_plot[hues].astype(str).agg('-'.join, axis=1)\n",
    "            _ = chart_type(data=data_to_plot, x=x, y=y, hue='hues', palette='viridis')\n",
    "            plt.legend(title=f'{y} for {x}, sorted by {[h + \", \" for h in hues]}', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        elif len(hues) == 1:\n",
    "            data_to_plot['hues'] = data_to_plot[hues[0]]\n",
    "            _ = chart_type(data=data_to_plot, x=x, y=y, hue='hues', palette='viridis')\n",
    "            plt.legend(title=f'{y} for {x}, sorted by {[h + \", \" for h in hues]}', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            _ = chart_type(data=data_to_plot, x=x, y=y)\n",
    "            plt.legend(title=f'{y} for {x}, sorted by {[h + \", \" for h in hues]}', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            #plt.show()\n",
    "\n",
    "            plt.axhline(y=1, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "        plt.axhline(y=1, color='red', linestyle='--', linewidth=2)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    except (KeyError, ValueError) as e:\n",
    "        print(f\"You've passed an incorrect column name.\\n The correct ones are: \\n{data_to_plot.columns}\\nException: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "noisy_runs = pd.read_csv('runs_export.csv')\n",
    "noisy_runs = noisy_runs.dropna()\n",
    "noisy_runs = noisy_runs['artefact_path'].apply(json.loads)\n",
    "strings = [\"results/results_statevector_HD135_all.csv\",\n",
    "           \"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'multiangle'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{4},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{4},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{7},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{7},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\"]\n",
    "\n",
    "\"\"\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'multiangle'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{1},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{4},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{4},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{7},'warm_start'{False,True},'problem_type'{'minvertexcover'}}.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'noisy_sampling'},'qaoa_variant'{'vanilla'},'param_initialization'{'gaussian'},'depth'{7},'warm_start'{True},'problem_type'{'minvertexcover'},'hamming_dist'{1,3,5}}.csv\"]\n",
    "\"\"\"\n",
    "strings_lagrange = [\"results/results_papergraph_{'backend_mode'{'statevector'},'qaoa_variant'{'multiangle','vanilla'},'param_initialization'{'gaussian'},'depth'{1,4},'warm_start'{True},'problem_type'{'minvertexcover'},'lagrangian_multiplier.csv\",\n",
    "\"results/results_papergraph_{'backend_mode'{'statevector'},'qaoa_variant'{'multiangle','vanilla'},'param_initialization'{'gaussian'},'depth'{1,4},'warm_start'{False,True},'problem_type'{'minvertexcover'},'lagrangian_mult.csv\"\n",
    "   ]\n",
    " \n",
    "\n",
    "for file in strings:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        #print(f\"File: {file}\")\n",
    "        #print(df['graph_name'].value_counts())\n",
    "        #print(\"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file}\")\n",
    "\n",
    "if len(strings) >1:\n",
    "    results = pd.concat([pd.read_csv(path,index_col=0) for path in strings])\n",
    "\n",
    "else:\n",
    "    results = pd.read_csv(strings[0])\n",
    "\n",
    "\n",
    "\n",
    "for file in strings_lagrange:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"File: {file}\")\n",
    "        print(df['graph_name'].value_counts())\n",
    "        print(\"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file}\")\n",
    "\n",
    "if len(strings_lagrange) >1:\n",
    "    results_lagrange = pd.concat([pd.read_csv(path,index_col=0) for path in strings_lagrange])\n",
    "\n",
    "else:\n",
    "    results_lagrange = pd.read_csv(strings_lagrange[0])\n",
    "\n",
    "results = pd.concat([results, noisy_runs])\n",
    "results_lagrange = results_lagrange[((results_lagrange['qaoa_variant'] == 'multiangle') & (results_lagrange['depth'] == 1)) |\n",
    "              ((results_lagrange['qaoa_variant'] == 'vanilla') & (results_lagrange['depth'] == 4))]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
